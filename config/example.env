# Infinite Memory Inference API - Configuration
# CORRECT settings for TheBloke models

# Model Configuration
MODEL_NAME=TheBloke/Mistral-7B-Instruct-v0.2-GPTQ
MODEL_QUANTIZATION=gptq
GPU_MEMORY_UTILIZATION=0.85
MAX_MODEL_LEN=8192

# Vector DB
VECTOR_DB_BACKEND=chromadb
CHROMA_PERSIST_DIR=./data/chroma_db

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
API_KEYS=

# Memory Configuration
CACHE_CAPACITY=1000
TTL_DAYS=90
CONTEXT_RETRIEVAL_K=3
MAX_CONTEXT_TOKENS=4096

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60

# Logging
LOG_LEVEL=INFO
LOG_FILE=./data/logs/api.log